{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📘 Motivation for Fine-tuning Models\n",
    "\n",
    "Welcome to the first notebook in our **Finetune-Your-Own-Model** tutorial series! Before diving into the technical details, let's understand *why* fine-tuning has become such a pivotal technique in modern machine learning.\n",
    "\n",
    "## What You'll Learn\n",
    "- What fine-tuning is and how it differs from training from scratch\n",
    "- When you should consider fine-tuning a pre-trained model\n",
    "- The tangible benefits and potential limitations\n",
    "- Real-world examples showing the impact of fine-tuning\n",
    "- A framework to decide if fine-tuning is right for your project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Fine-tuning vs. Training from Scratch\n",
    "\n",
    "### The Traditional Approach: Training from Scratch\n",
    "\n",
    "Historically, building a machine learning model involved:\n",
    "- Collecting large amounts of task-specific data\n",
    "- Designing a model architecture\n",
    "- Initializing model weights randomly\n",
    "- Training the model until convergence (often days or weeks)\n",
    "\n",
    "This approach requires substantial computational resources, extensive datasets, and significant time investment.\n",
    "\n",
    "### The Modern Approach: Fine-tuning\n",
    "\n",
    "Fine-tuning leverages **transfer learning** by:\n",
    "- Starting with a pre-trained model that has learned general features from a large dataset\n",
    "- Adapting this model to a specific downstream task using a smaller, task-specific dataset\n",
    "- Updating some or all of the pre-trained weights to better fit the new task\n",
    "\n",
    "Think of it as teaching a model that already \"understands\" the world to focus on your specific problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's visualize the difference between training from scratch and fine-tuning\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data to simulate learning curves\n",
    "epochs = np.arange(1, 101)\n",
    "accuracy_scratch = 70 * (1 - np.exp(-epochs/30)) + 10 + np.random.normal(0, 1, 100)  # Slower convergence\n",
    "accuracy_finetune = 85 * (1 - np.exp(-epochs/10)) + 10 + np.random.normal(0, 0.5, 100)  # Faster convergence, higher ceiling\n",
    "\n",
    "# Create figure with secondary y-axis\n",
    "fig = make_subplots(specs=[[{\"secondary_y\": False}]])\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=accuracy_scratch, name=\"Training from Scratch\", line=dict(color=\"#EF553B\", width=2)),\n",
    ")\n",
    "\n",
    "fig.add_trace(\n",
    "    go.Scatter(x=epochs, y=accuracy_finetune, name=\"Fine-tuning\", line=dict(color=\"#636EFA\", width=2)),\n",
    ")\n",
    "\n",
    "# Add annotations\n",
    "fig.add_annotation(\n",
    "    x=80, y=accuracy_finetune[79],\n",
    "    text=\"Higher performance\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=50, ay=-40\n",
    ")\n",
    "\n",
    "fig.add_annotation(\n",
    "    x=20, y=accuracy_finetune[19],\n",
    "    text=\"Faster convergence\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=50, ay=30\n",
    ")\n",
    "\n",
    "# Add figure title and axis labels\n",
    "fig.update_layout(\n",
    "    title=\"Learning Curves: Fine-tuning vs Training from Scratch\",\n",
    "    xaxis_title=\"Training Epochs\",\n",
    "    yaxis_title=\"Accuracy (%)\",\n",
    "    legend=dict(y=0.99, x=0.01),\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. When Should You Consider Fine-tuning?\n",
    "\n",
    "Fine-tuning is particularly advantageous in these common scenarios:\n",
    "\n",
    "### Domain Adaptation\n",
    "- You need a model for a specific domain (medical, legal, financial) but have limited domain-specific data\n",
    "- Example: Adapting a general language model to understand medical terminology and relationships\n",
    "\n",
    "### Task Specialization\n",
    "- You want to perform a specific task that's related to what the pre-trained model has learned\n",
    "- Example: Taking an image classification model and fine-tuning it for object detection\n",
    "\n",
    "### Resource Constraints\n",
    "- You have limited computational resources or training time\n",
    "- You have a small dataset that would be insufficient for training from scratch\n",
    "\n",
    "### Low-Resource Languages or Domains\n",
    "- You're working with languages or domains that have limited available data\n",
    "- Example: Fine-tuning a multilingual model for a specific low-resource language\n",
    "\n",
    "### Incremental Learning\n",
    "- You want to update an existing model with new data or capabilities without starting over\n",
    "- Example: Adding recognition of new product categories to an existing product classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the relationship between dataset size and model performance\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Create sample data\n",
    "dataset_sizes = np.array([100, 500, 1000, 5000, 10000, 50000, 100000, 500000])\n",
    "log_sizes = np.log10(dataset_sizes)\n",
    "\n",
    "# Performance curves (simulated)\n",
    "performance_scratch = 30 + 55 * (1 - np.exp(-(log_sizes - 2) / 1.5))\n",
    "performance_finetune = 65 + 30 * (1 - np.exp(-(log_sizes - 2) / 1))\n",
    "\n",
    "# Create the figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataset_sizes, \n",
    "    y=performance_scratch,\n",
    "    mode='lines+markers',\n",
    "    name='Training from Scratch',\n",
    "    line=dict(color='#EF553B', width=2),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=dataset_sizes, \n",
    "    y=performance_finetune,\n",
    "    mode='lines+markers',\n",
    "    name='Fine-tuning',\n",
    "    line=dict(color='#636EFA', width=2),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "\n",
    "# Add a vertical line to indicate a \"typical\" small dataset scenario\n",
    "fig.add_shape(\n",
    "    type=\"line\",\n",
    "    x0=1000, y0=0,\n",
    "    x1=1000, y1=100,\n",
    "    line=dict(color=\"gray\", width=1, dash=\"dash\"),\n",
    ")\n",
    "\n",
    "# Add annotation for the small dataset scenario\n",
    "fig.add_annotation(\n",
    "    x=1000,\n",
    "    y=45,\n",
    "    text=\"Small dataset<br>scenario\",\n",
    "    showarrow=False,\n",
    "    yshift=10,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "# Add annotation for the performance gap\n",
    "fig.add_annotation(\n",
    "    x=1000,\n",
    "    y=(performance_finetune[2] + performance_scratch[2]) / 2,\n",
    "    text=f\"Performance gap:<br>{performance_finetune[2] - performance_scratch[2]:.1f}%\",\n",
    "    showarrow=True,\n",
    "    arrowhead=2,\n",
    "    arrowsize=1,\n",
    "    arrowwidth=1,\n",
    "    arrowcolor=\"#555\",\n",
    "    ax=50,\n",
    "    ay=0,\n",
    "    font=dict(size=12)\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Model Performance vs. Dataset Size',\n",
    "    xaxis=dict(\n",
    "        title='Dataset Size (number of examples)',\n",
    "        type='log',\n",
    "        tickvals=dataset_sizes,\n",
    "        ticktext=[str(s) for s in dataset_sizes],\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Performance (accuracy %)',\n",
    "        range=[30, 100]\n",
    "    ),\n",
    "    legend=dict(y=0.99, x=0.01),\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    hovermode=\"x unified\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Benefits of Fine-tuning\n",
    "\n",
    "### Reduced Computational Costs\n",
    "- **Training from scratch**: May require hundreds of GPUs running for weeks\n",
    "- **Fine-tuning**: Can often be done on a single GPU in hours or days\n",
    "- Example: Training GPT-3 from scratch cost millions of dollars, but fine-tuning it can cost under $100\n",
    "\n",
    "### Faster Development Cycles\n",
    "- Shorter training times mean faster iterations and experimentation\n",
    "- Enables rapid prototyping and validation of ideas\n",
    "- Typical fine-tuning runs take hours instead of weeks\n",
    "\n",
    "### Higher Performance with Less Data\n",
    "- Pre-trained models already contain general knowledge that transfers to new tasks\n",
    "- Fine-tuned models often outperform models trained from scratch, especially with limited data\n",
    "- Can achieve state-of-the-art results with just hundreds or thousands of examples\n",
    "\n",
    "### Democratization of Advanced AI\n",
    "- Makes cutting-edge models accessible to researchers and developers with limited resources\n",
    "- Enables specialized applications that wouldn't be feasible with from-scratch training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the computational cost comparison\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Data for computational resources\n",
    "models = ['BERT-base', 'RoBERTa-large', 'GPT-2', 'ViT-Large', 'T5-large']\n",
    "training_costs = [3000, 15000, 30000, 10000, 25000]  # Approximate GPU hours\n",
    "finetuning_costs = [10, 40, 100, 30, 80]  # Approximate GPU hours\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add bars\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=training_costs,\n",
    "    name='Training from Scratch',\n",
    "    marker_color='#EF553B'\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    x=models,\n",
    "    y=finetuning_costs,\n",
    "    name='Fine-tuning',\n",
    "    marker_color='#636EFA'\n",
    "))\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='Computational Cost: Training vs. Fine-tuning (Lower is Better)',\n",
    "    xaxis_title='Model Architecture',\n",
    "    yaxis_title='GPU Hours (log scale)',\n",
    "    yaxis_type='log',  # Log scale to show the dramatic difference\n",
    "    barmode='group',\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    legend=dict(y=0.99, x=0.99, xanchor='right')\n",
    ")\n",
    "\n",
    "# Add annotations to highlight the difference\n",
    "for i, model in enumerate(models):\n",
    "    ratio = training_costs[i] / finetuning_costs[i]\n",
    "    fig.add_annotation(\n",
    "        x=i,\n",
    "        y=finetuning_costs[i] * 2,\n",
    "        text=f\"{ratio:.0f}x faster\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10, color='white'),\n",
    "        bgcolor='rgba(0,0,0,0.5)',\n",
    "        bordercolor='rgba(0,0,0,0)',\n",
    "        borderwidth=1,\n",
    "        borderpad=2,\n",
    "        opacity=0.8\n",
    "    )\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Trade-offs and Limitations\n",
    "\n",
    "While fine-tuning offers many advantages, it's important to understand its limitations:\n",
    "\n",
    "### Inheriting Biases and Limitations\n",
    "- Fine-tuned models inherit biases present in the pre-trained model\n",
    "- Example: A language model trained on internet text may contain social biases that transfer to fine-tuned applications\n",
    "\n",
    "### Catastrophic Forgetting\n",
    "- Aggressive fine-tuning can cause the model to \"forget\" useful general knowledge from pre-training\n",
    "- Mitigation strategies include:\n",
    "  - Parameter-efficient fine-tuning (PEFT)\n",
    "  - Careful learning rate scheduling\n",
    "  - Regularization techniques\n",
    "\n",
    "### Domain Mismatch\n",
    "- If your target domain differs significantly from the pre-training domain, benefits may be limited\n",
    "- Example: Using a model pre-trained on natural images for medical imaging may require more extensive fine-tuning\n",
    "\n",
    "### Architectural Constraints\n",
    "- You're constrained by the architecture of the pre-trained model\n",
    "- Making significant architectural changes often negates the benefits of pre-training\n",
    "\n",
    "### Technical Complexity\n",
    "- Fine-tuning can involve complex hyperparameter tuning\n",
    "- Requires understanding of the pre-trained model's architecture and capabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize catastrophic forgetting during fine-tuning\n",
    "import plotly.graph_objects as go\n",
    "import numpy as np\n",
    "\n",
    "# Simulated data\n",
    "epochs = np.arange(1, 51)\n",
    "target_task_perf = 65 + 30 * (1 - np.exp(-epochs/10))  # Performance on the target task improves\n",
    "general_knowledge = 95 - 30 * (1 - np.exp(-epochs/15))  # Performance on general tasks declines\n",
    "balanced_approach = 95 - 10 * (1 - np.exp(-epochs/25))  # Less forgetting with careful tuning\n",
    "\n",
    "# Create figure\n",
    "fig = go.Figure()\n",
    "\n",
    "# Add traces\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=target_task_perf,\n",
    "    mode='lines',\n",
    "    name='Target Task Performance',\n",
    "    line=dict(color='#636EFA', width=2)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=general_knowledge,\n",
    "    mode='lines',\n",
    "    name='General Knowledge (Aggressive Fine-tuning)',\n",
    "    line=dict(color='#EF553B', width=2)\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=epochs,\n",
    "    y=balanced_approach,\n",
    "    mode='lines',\n",
    "    name='General Knowledge (Careful Fine-tuning)',\n",
    "    line=dict(color='#00CC96', width=2, dash='dash')\n",
    "))\n",
    "\n",
    "# Add annotation for catastrophic forgetting\n",
    "fig.add_annotation(\n",
    "    x=40,\n",
    "    y=general_knowledge[39],\n",
    "    text=\"Catastrophic<br>Forgetting\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=40,\n",
    "    ay=-30\n",
    ")\n",
    "\n",
    "# Add annotation for the balanced approach\n",
    "fig.add_annotation(\n",
    "    x=40,\n",
    "    y=balanced_approach[39],\n",
    "    text=\"Balanced<br>Approach\",\n",
    "    showarrow=True,\n",
    "    arrowhead=1,\n",
    "    ax=-40,\n",
    "    ay=-20\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='The Challenge of Catastrophic Forgetting During Fine-tuning',\n",
    "    xaxis_title='Fine-tuning Epochs',\n",
    "    yaxis_title='Performance (%)',\n",
    "    template=\"plotly_white\",\n",
    "    height=500,\n",
    "    hovermode=\"x unified\",\n",
    "    legend=dict(y=0.99, x=0.01)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Real-World Examples: Before and After Fine-tuning\n",
    "\n",
    "Let's look at some concrete examples of fine-tuning success stories across different domains:\n",
    "\n",
    "### Example 1: Text Classification - Sentiment Analysis\n",
    "\n",
    "**Before Fine-tuning**: Using BERT pre-trained on general text\n",
    "- Accuracy on financial sentiment dataset: 76%\n",
    "- Struggles with domain-specific terminology and context\n",
    "\n",
    "**After Fine-tuning**: BERT fine-tuned on financial news and reports\n",
    "- Accuracy: 92%\n",
    "- Correctly interprets financial terms and industry-specific sentiment\n",
    "- Training required only 5,000 labeled examples instead of millions\n",
    "\n",
    "### Example 2: Image Classification - Medical Imaging\n",
    "\n",
    "**Before Fine-tuning**: ResNet-50 pre-trained on ImageNet\n",
    "- Accuracy on chest X-ray classification: 68%\n",
    "- Fails to identify subtle medical features\n",
    "\n",
    "**After Fine-tuning**: ResNet-50 fine-tuned on medical images\n",
    "- Accuracy: 87%\n",
    "- Successfully identifies pneumonia, COVID-19 markers, and other conditions\n",
    "- Achieved with only 15,000 labeled medical images\n",
    "\n",
    "### Example 3: Natural Language Generation - Legal Document Drafting\n",
    "\n",
    "**Before Fine-tuning**: GPT-2 generating legal text\n",
    "- Generated text uses casual language, lacks proper structure\n",
    "- Inaccurate use of legal terminology\n",
    "- Low usability score from legal professionals: 3.2/10\n",
    "\n",
    "**After Fine-tuning**: GPT-2 fine-tuned on legal documents\n",
    "- Generates properly structured legal documents with appropriate terminology\n",
    "- Maintains formal tone and follows legal writing conventions\n",
    "- Usability score from legal professionals: 7.8/10\n",
    "- Fine-tuned with only 10,000 examples of legal documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize real-world performance improvements\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Data\n",
    "domains = ['Financial Sentiment', 'Medical Imaging', 'Legal Document Generation']\n",
    "before_scores = [76, 68, 32]  # Before fine-tuning (percentage)\n",
    "after_scores = [92, 87, 78]   # After fine-tuning (percentage)\n",
    "data_sizes = [5000, 15000, 10000]  # Dataset sizes used for fine-tuning\n",
    "models = ['BERT', 'ResNet-50', 'GPT-2']  # Base models\n",
    "\n",
    "# Create subplots\n",
    "fig = make_subplots(rows=1, cols=3, \n",
    "                    subplot_titles=domains,\n",
    "                    specs=[[{'type': 'domain'}, {'type': 'domain'}, {'type': 'domain'}]])\n",
    "\n",
    "colors = ['#EF553B', '#636EFA']\n",
    "labels = ['Before Fine-tuning', 'After Fine-tuning']\n",
    "\n",
    "# Add pie charts\n",
    "for i, domain in enumerate(domains):\n",
    "    fig.add_trace(go.Pie(\n",
    "        labels=labels,\n",
    "        values=[before_scores[i], after_scores[i] - before_scores[i]],\n",
    "        name=domain,\n",
    "        marker=dict(colors=colors),\n",
    "        textinfo='label+percent',\n",
    "        hole=.3,\n",
    "        hoverinfo='label+percent+name',\n",
    "        showlegend=(i==0)  # Only show legend for the first pie\n",
    "    ), row=1, col=i+1)\n",
    "    \n",
    "    # Add annotations\n",
    "    fig.add_annotation(\n",
    "        text=f\"<b>Model:</b> {models[i]}<br><b>Data:</b> {data_sizes[i]} examples\",\n",
    "        x=0.5, y=-0.2,\n",
    "        xref=f\"x{i+1}\", yref=f\"y{i+1}\",\n",
    "        showarrow=False,\n",
    "        font=dict(size=10)\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title_text=\"Performance Improvements After Fine-tuning Across Domains\",\n",
    "    height=500,\n",
    "    template=\"plotly_white\",\n",
    "    legend=dict(y=1.1, x=0.5, xanchor='center', orientation='h'),\n",
    "    margin=dict(t=120, b=80)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cost-Benefit Analysis Framework\n",
    "\n",
    "To decide whether fine-tuning is the right approach for your project, consider this framework:\n",
    "\n",
    "### Step 1: Assess Your Resources\n",
    "- **Data availability**: How much task-specific data do you have?\n",
    "- **Compute resources**: What GPU/TPU resources can you access?\n",
    "- **Time constraints**: What's your development timeline?\n",
    "- **Budget**: What's your financial constraint for training?\n",
    "\n",
    "### Step 2: Evaluate Task Similarity\n",
    "- How similar is your task to what the pre-trained model was trained on?\n",
    "- Are there domain-specific nuances that the pre-trained model might miss?\n",
    "- Is there a pre-trained model available that's reasonably close to your domain?\n",
    "\n",
    "### Step 3: Consider Performance Requirements\n",
    "- What level of performance do you need for your application?\n",
    "- Is there a minimum accuracy/quality threshold your solution must meet?\n",
    "- How important is inference speed vs. absolute accuracy?\n",
    "\n",
    "### Step 4: Calculate ROI\n",
    "- Compare the estimated costs (time, compute, data collection) of fine-tuning vs. training from scratch\n",
    "- Estimate the performance difference between the approaches\n",
    "- Consider the opportunity cost of longer development time\n",
    "\n",
    "### Decision Matrix\n",
    "\n",
    "| Scenario | Recommendation |\n",
    "|----------|----------------|\n",
    "| Limited data (<10k examples) | **Fine-tune** - Training from scratch likely won't work well |\n",
    "| Limited compute | **Fine-tune** - Significantly lower resource requirements |\n",
    "| Tight timeline | **Fine-tune** - Faster to reach acceptable performance |\n",
    "| Very different domain from available pre-trained models | **Consider domain-adaptive pre-training** before fine-tuning |\n",
    "| Need for architectural innovation | **Train from scratch** if your architecture differs significantly |\n",
    "| Extremely high performance requirements | **Fine-tune, then distill** for optimal results |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive decision tool for fine-tuning\n",
    "import plotly.graph_objects as go\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Create interactive widgets\n",
    "data_size = widgets.IntSlider(\n",
    "    value=5000,\n",
    "    min=100,\n",
    "    max=100000,\n",
    "    step=100,\n",
    "    description='Dataset Size:',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "domain_similarity = widgets.IntSlider(\n",
    "    value=70,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Domain Similarity to Pre-trained Data (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "compute_constraint = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Compute Constraint Level (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "time_constraint = widgets.IntSlider(\n",
    "    value=50,\n",
    "    min=0,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Time Constraint Level (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "performance_requirement = widgets.IntSlider(\n",
    "    value=80,\n",
    "    min=50,\n",
    "    max=100,\n",
    "    step=5,\n",
    "    description='Performance Requirement (%):',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "# Function to update the recommendation\n",
    "def update_recommendation(change):\n",
    "    # Calculate scores\n",
    "    finetune_score = 0\n",
    "    scratch_score = 0\n",
    "    \n",
    "    # Data size factor\n",
    "    if data_size.value < 1000:\n",
    "        finetune_score += 30\n",
    "        scratch_score -= 20\n",
    "    elif data_size.value < 10000:\n",
    "        finetune_score += 20\n",
    "        scratch_score -= 5\n",
    "    elif data_size.value < 50000:\n",
    "        finetune_score += 10\n",
    "        scratch_score += 10\n",
    "    else:\n",
    "        finetune_score += 5\n",
    "        scratch_score += 20\n",
    "    \n",
    "    # Domain similarity factor\n",
    "    if domain_similarity.value < 30:\n",
    "        finetune_score -= 15\n",
    "        scratch_score += 15\n",
    "    elif domain_similarity.value < 60:\n",
    "        finetune_score += 5\n",
    "        scratch_score += 5\n",
    "    else:\n",
    "        finetune_score += 20\n",
    "        scratch_score -= 5\n",
    "    \n",
    "    # Compute constraint factor\n",
    "    if compute_constraint.value > 70:  # High constraint\n",
    "        finetune_score += 25\n",
    "        scratch_score -= 15\n",
    "    elif compute_constraint.value > 40:  # Medium constraint\n",
    "        finetune_score += 15\n",
    "        scratch_score -= 5\n",
    "    else:  # Low constraint\n",
    "        finetune_score += 5\n",
    "        scratch_score += 10\n",
    "    \n",
    "    # Time constraint factor\n",
    "    if time_constraint.value > 70:  # High constraint\n",
    "        finetune_score += 25\n",
    "        scratch_score -= 15\n",
    "    elif time_constraint.value > 40:  # Medium constraint\n",
    "        finetune_score += 15\n",
    "        scratch_score -= 5\n",
    "    else:  # Low constraint\n",
    "        finetune_score += 5\n",
    "        scratch_score += 10\n",
    "    \n",
    "    # Performance requirement factor\n",
    "    if performance_requirement.value > 90:  # Very high\n",
    "        if domain_similarity.value > 80:  # Similar domain\n",
    "            finetune_score += 15\n",
    "            scratch_score += 10\n",
    "        else:  # Different domain\n",
    "            finetune_score += 5\n",
    "            scratch_score += 15\n",
    "    elif performance_requirement.value > 75:  # High\n",
    "        finetune_score += 15\n",
    "        scratch_score += 5\n",
    "    else:  # Moderate\n",
    "        finetune_score += 20\n",
    "        scratch_score -= 5\n",
    "    \n",
    "    # Normalize scores to 0-100\n",
    "    max_possible = 100\n",
    "    finetune_score = min(max(finetune_score, 0), 100)\n",
    "    scratch_score = min(max(scratch_score, 0), 100)\n",
    "    \n",
    "    # Update the gauge chart\n",
    "    with output:\n",
    "        fig = go.Figure()\n",
    "        \n",
    "        fig.add_trace(go.Indicator(\n",
    "            mode = \"gauge+number\",\n",
    "            value = finetune_score,\n",
    "            title = {'text': \"Fine-tuning Score\"},\n",
    "            domain = {'x': [0, 0.45], 'y': [0, 1]},\n",
    "            gauge = {\n",
    "                'axis': {'range': [0, 100]},\n",
    "                'bar': {'color': \"#636EFA\"},\n",
    "                'steps': [\n",
    "                    {'range': [0, 33], 'color': \"#EF553B\"},\n",
    "                    {'range': [33, 66], 'color': \"#FFA15A\"},\n",
    "                    {'range': [66, 100], 'color': \"#00CC96\"}\n",
    "                ]\n",
    "            }\n",
    "        ))\n",
    "        \n",
    "        fig.add_trace(go.Indicator(\n",
    "            mode = \"gauge+number\",\n",
    "            value = scratch_score,\n",
    "            title = {'text': \"Training from Scratch Score\"},\n",
    "            domain = {'x': [0.55, 1], 'y': [0, 1]},\n",
    "            gauge = {\n",
    "                'axis': {'range': [0, 100]},\n",
    "                'bar': {'color': \"#EF553B\"},\n",
    "                'steps': [\n",
    "                    {'range': [0, 33], 'color': \"#EF553B\"},\n",
    "                    {'range': [33, 66], 'color': \"#FFA15A\"},\n",
    "                    {'range': [66, 100], 'color': \"#00CC96\"}\n",
    "                ]\n",
    "            }\n",
    "        ))\n",
    "        \n",
    "        # Determine recommendation\n",
    "        if finetune_score > scratch_score + 20:\n",
    "            recommendation = \"<b>Strong recommendation: Fine-tune</b><br>Fine-tuning is clearly the better approach for your scenario.\"\n",
    "            rec_color = \"#00CC96\"\n",
    "        elif finetune_score > scratch_score:\n",
    "            recommendation = \"<b>Recommendation: Fine-tune</b><br>Fine-tuning has an edge, but consider your specific requirements.\"\n",
    "            rec_color = \"#00CC96\"\n",
    "        elif scratch_score > finetune_score + 20:\n",
    "            recommendation = \"<b>Strong recommendation: Train from scratch</b><br>Your scenario favors training a custom model from scratch.\"\n",
    "            rec_color = \"#EF553B\"\n",
    "        else:\n",
    "            recommendation = \"<b>Recommendation: Train from scratch</b><br>Training from scratch has a slight advantage, but fine-tuning could still work.\"\n",
    "            rec_color = \"#EF553B\"\n",
    "        \n",
    "        # Add recommendation annotation\n",
    "        fig.add_annotation(\n",
    "            xref=\"paper\", yref=\"paper\",\n",
    "            x=0.5, y=0.25,\n",
    "            text=recommendation,\n",
    "            showarrow=False,\n",
    "            font=dict(size=14, color=rec_color),\n",
    "            align=\"center\",\n",
    "            bgcolor=\"rgba(255, 255, 255, 0.8)\",\n",
    "            bordercolor=rec_color,\n",
    "            borderwidth=2,\n",
    "            borderpad=4,\n",
    "            width=400\n",
    "        )\n",
    "        \n",
    "        fig.update_layout(\n",
    "            title=\"Fine-tuning Decision Assistant\",\n",
    "            height=400,\n",
    "            margin=dict(t=100, b=100, l=50, r=50),\n",
    "            template=\"plotly_white\"\n",
    "        )\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "# Connect the update function to the widgets\n",
    "data_size.observe(update_recommendation, names='value')\n",
    "domain_similarity.observe(update_recommendation, names='value')\n",
    "compute_constraint.observe(update_recommendation, names='value')\n",
    "time_constraint.observe(update_recommendation, names='value')\n",
    "performance_requirement.observe(update_recommendation, names='value')\n",
    "\n",
    "# Create output area for the chart\n",
    "output = widgets.Output()\n",
    "\n",
    "# Display everything\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(value=\"<h3>Adjust the parameters below to see if fine-tuning is right for your project:</h3>\"),\n",
    "    data_size,\n",
    "    domain_similarity,\n",
    "    compute_constraint,\n",
    "    time_constraint,\n",
    "    performance_requirement,\n",
    "    output\n",
    "]))\n",
    "\n",
    "# Initialize the chart\n",
    "update_recommendation(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary: When to Fine-tune\n",
    "\n",
    "Fine-tuning is typically the right approach when:\n",
    "\n",
    "✅ You have limited labeled data for your specific task  \n",
    "✅ Your task is related to what the pre-trained model has learned  \n",
    "✅ You have computational constraints (time, budget, hardware)  \n",
    "✅ You need to iterate quickly  \n",
    "✅ You're working with a low-resource domain or language  \n",
    "\n",
    "Training from scratch might be better when:\n",
    "\n",
    "❌ Your domain is radically different from available pre-trained models  \n",
    "❌ You need a significantly different model architecture  \n",
    "❌ You have abundant domain-specific data  \n",
    "❌ You need to avoid inheriting biases from pre-trained models  \n",
    "\n",
    "## Next Steps\n",
    "\n",
    "Now that you understand the motivation and benefits of fine-tuning, let's move on to the next notebook: **Data Collection and Preparation**. This is arguably the most critical step in the fine-tuning process, as the quality and structure of your dataset will significantly impact the performance of your fine-tuned model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
