{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fine-tune Your Own Model with Hugging Face\n",
        "\n",
        "This notebook provides a comprehensive guide to fine-tuning pre-trained models using the Hugging Face ecosystem. We'll cover the entire workflow from understanding when to fine-tune, to deploying your model in production.\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Introduction and Motivation](#1-introduction-and-motivation)\n",
        "2. [Data Collection and Preparation](#2-data-collection-and-preparation)\n",
        "3. [Selecting a Base Model](#3-selecting-a-base-model)\n",
        "4. [Training and Fine-tuning](#4-training-and-fine-tuning)\n",
        "5. [Evaluation](#5-evaluation)\n",
        "6. [Deployment](#6-deployment)\n",
        "\n",
        "Let's start by installing the necessary libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install transformers datasets evaluate accelerate scikit-learn pandas matplotlib pillow torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import common libraries\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datasets import load_dataset, Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoFeatureExtractor\n",
        "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "import torch\n",
        "import evaluate\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from PIL import Image\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introduction and Motivation\n",
        "\n",
        "### Why Fine-tune Rather Than Train from Scratch?\n",
        "\n",
        "Fine-tuning leverages pre-trained models that have already learned general patterns from large datasets, allowing you to adapt them to your specific task with relatively little data and computational resources.\n",
        "\n",
        "Key advantages include:\n",
        "\n",
        "- **Data Efficiency**: Requires significantly less task-specific data (often 10-100x less)\n",
        "- **Computational Efficiency**: Training takes hours instead of weeks/months\n",
        "- **Better Performance**: Especially with limited data, fine-tuned models outperform models trained from scratch\n",
        "- **Knowledge Transfer**: Leverages general knowledge learned during pre-training\n",
        "\n",
        "### Common Scenarios and Use Cases\n",
        "\n",
        "Fine-tuning is particularly valuable in these scenarios:\n",
        "\n",
        "1. **Domain Adaptation**: Adapting general models to specific domains (medical, legal, financial)\n",
        "2. **Task Specialization**: Adapting a model trained for one task to a related task\n",
        "3. **Low-Resource Settings**: When you have limited data or computational resources\n",
        "4. **Multilingual Applications**: Adapting language models to specific languages\n",
        "5. **Rapid Prototyping**: Quickly testing ideas and solutions\n",
        "\n",
        "### When to Consider Fine-tuning\n",
        "\n",
        "| Scenario | Recommendation |\n",
        "|----------|----------------|\n",
        "| Limited data (<10k examples) | **Fine-tune** - Training from scratch likely won't work well |\n",
        "| Limited compute | **Fine-tune** - Significantly lower resource requirements |\n",
        "| Tight timeline | **Fine-tune** - Faster to reach acceptable performance |\n",
        "| Very different domain from available pre-trained models | **Consider domain-adaptive pre-training** before fine-tuning |\n",
        "| Need for architectural innovation | **Train from scratch** if your architecture differs significantly |\n",
        "\n",
        "Now that we understand why fine-tuning is valuable, let's dive into the most critical component of successful fine-tuning: your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data Collection and Preparation\n",
        "\n",
        "The quality, quantity, and relevance of your data is the single most important factor in fine-tuning success. Even the most sophisticated models can't overcome fundamental data problems (\"garbage in, garbage out\").\n",
        "\n",
        "### 2.1 Strategies for Data Collection\n",
        "\n",
        "Let's explore different approaches to collecting task-specific data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Using Existing Public Datasets\n",
        "\n",
        "The simplest approach is to leverage existing datasets from the Hugging Face Hub. Let's see how to browse and load datasets:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Loading a text classification dataset for sentiment analysis\n",
        "imdb_dataset = load_dataset(\"imdb\")\n",
        "\n",
        "# Examine the dataset structure\n",
        "print(f\"Dataset structure: {imdb_dataset}\")\n",
        "print(f\"Available splits: {list(imdb_dataset.keys())}\")\n",
        "print(f\"Number of examples in train split: {len(imdb_dataset['train'])}\")\n",
        "print(f\"Features: {imdb_dataset['train'].features}\")\n",
        "\n",
        "# Look at a sample example\n",
        "print(\"\\nSample example:\")\n",
        "print(imdb_dataset['train'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example: Loading an image classification dataset\n",
        "cifar10_dataset = load_dataset(\"cifar10\")\n",
        "\n",
        "# Examine the dataset structure\n",
        "print(f\"Dataset structure: {cifar10_dataset}\")\n",
        "print(f\"Available splits: {list(cifar10_dataset.keys())}\")\n",
        "print(f\"Number of examples in train split: {len(cifar10_dataset['train'])}\")\n",
        "print(f\"Features: {cifar10_dataset['train'].features}\")\n",
        "\n",
        "# Visualize a few examples\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for i, idx in enumerate(range(10)):\n",
        "    example = cifar10_dataset['train'][idx]\n",
        "    axes[i].imshow(example['img'])\n",
        "    axes[i].set_title(f\"Label: {example['label']}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Creating Custom Datasets from Structured Sources\n",
        "\n",
        "Often, you'll need to create a custom dataset from existing structured sources like CSV files or JSON data. Let's see how to create a custom dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a sample CSV file with product reviews\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Generate synthetic product review data\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "\n",
        "# Create product categories\n",
        "categories = ['Electronics', 'Clothing', 'Home', 'Books', 'Beauty']\n",
        "\n",
        "# Generate synthetic reviews\n",
        "positive_templates = [\n",
        "    \"I love this {category} product! It's exactly what I needed.\",\n",
        "    \"This {category} item exceeded my expectations. Highly recommend!\",\n",
        "    \"Great quality {category} product, worth every penny.\",\n",
        "    \"The best {category} purchase I've made this year.\",\n",
        "    \"Excellent {category} item, works perfectly.\"\n",
        "]\n",
        "\n",
        "negative_templates = [\n",
        "    \"Disappointed with this {category} product. Would not recommend.\",\n",
        "    \"Poor quality {category} item, broke after a few uses.\",\n",
        "    \"This {category} product didn't meet my expectations at all.\",\n",
        "    \"Waste of money for this {category} item.\",\n",
        "    \"The {category} product has serious design flaws.\"\n",
        "]\n",
        "\n",
        "# Generate data\n",
        "data = []\n",
        "for i in range(n_samples):\n",
        "    category = np.random.choice(categories)\n",
        "    rating = np.random.randint(1, 6)  # 1-5 star rating\n",
        "    \n",
        "    if rating >= 4:  # Positive review\n",
        "        template = np.random.choice(positive_templates)\n",
        "        sentiment = 'positive'\n",
        "    else:  # Negative review\n",
        "        template = np.random.choice(negative_templates)\n",
        "        sentiment = 'negative'\n",
        "    \n",
        "    review = template.format(category=category.lower())\n",
        "    \n",
        "    # Add some noise/variation\n",
        "    if np.random.random() < 0.3:\n",
        "        review = review + \" \" + np.random.choice([\"Thank you!\", \"Never again.\", \"Will buy again.\", \"Save your money.\"])\n",
        "    \n",
        "    data.append({\n",
        "        'review_id': i,\n",
        "        'category': category,\n",
        "        'rating': rating,\n",
        "        'review_text': review,\n",
        "        'sentiment': sentiment\n",
        "    })\n",
        "\n",
        "# Create DataFrame and save to CSV\n",
        "df = pd.DataFrame(data)\n",
        "csv_path = 'product_reviews.csv'\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Display the first few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert the CSV to a Hugging Face dataset\n",
        "from datasets import Dataset, DatasetDict\n",
        "\n",
        "# Load the CSV data\n",
        "df = pd.read_csv('product_reviews.csv')\n",
        "\n",
        "# Create train/validation/test splits (80/10/10)\n",
        "df = df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle\n",
        "train_size = int(0.8 * len(df))\n",
        "val_size = int(0.1 * len(df))\n",
        "\n",
        "train_df = df[:train_size]\n",
        "val_df = df[train_size:train_size+val_size]\n",
        "test_df = df[train_size+val_size:]\n",
        "\n",
        "# Convert to Hugging Face datasets\n",
        "train_dataset = Dataset.from_pandas(train_df)\n",
        "val_dataset = Dataset.from_pandas(val_df)\n",
        "test_dataset = Dataset.from_pandas(test_df)\n",
        "\n",
        "# Combine into a DatasetDict\n",
        "product_reviews_dataset = DatasetDict({\n",
        "    'train': train_dataset,\n",
        "    'validation': val_dataset,\n",
        "    'test': test_dataset\n",
        "})\n",
        "\n",
        "# Examine the dataset\n",
        "print(f\"Dataset structure: {product_reviews_dataset}\")\n",
        "print(f\"Number of examples in train split: {len(product_reviews_dataset['train'])}\")\n",
        "print(f\"Features: {product_reviews_dataset['train'].features}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Data Cleaning and Preprocessing\n",
        "\n",
        "Once you've collected your data, the next critical step is cleaning and preprocessing. The specific techniques depend on the data modality (text, image, audio, etc.)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Text Data Preprocessing\n",
        "\n",
        "For text data, common preprocessing steps include:\n",
        "- Removing HTML tags and special characters\n",
        "- Handling contractions and abbreviations\n",
        "- Normalizing case (lowercase/uppercase)\n",
        "- Removing or replacing numbers\n",
        "- Handling punctuation\n",
        "\n",
        "Let's implement these for our product reviews dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Text preprocessing function\n",
        "import re\n",
        "\n",
        "def preprocess_text(text):\n",
        "    \"\"\"Basic text preprocessing for fine-tuning\"\"\"\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "    \n",
        "    # Remove HTML tags\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    \n",
        "    # Replace contractions\n",
        "    contractions = {\n",
        "        \"won't\": \"will not\",\n",
        "        \"can't\": \"cannot\",\n",
        "        \"n't\": \" not\",\n",
        "        \"'re\": \" are\",\n",
        "        \"'s\": \" is\",\n",
        "        \"'d\": \" would\",\n",
        "        \"'ll\": \" will\",\n",
        "        \"'ve\": \" have\",\n",
        "        \"'m\": \" am\"\n",
        "    }\n",
        "    for contraction, expansion in contractions.items():\n",
        "        text = text.replace(contraction, expansion)\n",
        "    \n",
        "    # Remove excessive whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    \n",
        "    return text\n",
        "\n",
        "# Apply preprocessing to a sample\n",
        "sample_text = df['review_text'].iloc[0]\n",
        "print(f\"Original text: {sample_text}\")\n",
        "print(f\"Preprocessed text: {preprocess_text(sample_text)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Apply preprocessing to the entire dataset\n",
        "def preprocess_dataset(dataset):\n",
        "    \"\"\"Apply text preprocessing to a dataset\"\"\"\n",
        "    return dataset.map(\n",
        "        lambda example: {'processed_text': preprocess_text(example['review_text'])}\n",
        "    )\n",
        "\n",
        "processed_dataset = preprocess_dataset(product_reviews_dataset)\n",
        "print(processed_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Image Data Preprocessing\n",
        "\n",
        "For image data, common preprocessing steps include:\n",
        "- Resizing to a consistent dimension\n",
        "- Normalization (scaling pixel values)\n",
        "- Data augmentation (for training)\n",
        "\n",
        "With Hugging Face, much of this is handled by the model's feature extractor or image processor. Let's see how this works with CIFAR-10:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a pre-trained image processor for ViT\n",
        "from transformers import AutoImageProcessor\n",
        "\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-224\")\n",
        "\n",
        "# Function to preprocess images\n",
        "def preprocess_images(examples):\n",
        "    \"\"\"Process images for the model\"\"\"\n",
        "    # Process the images with the image processor\n",
        "    # This handles resizing, normalization, etc.\n",
        "    inputs = image_processor(examples[\"img\"], return_tensors=\"pt\")\n",
        "    return inputs\n",
        "\n",
        "# Process a sample image\n",
        "sample_image = cifar10_dataset[\"train\"][0][\"img\"]\n",
        "processed_image = preprocess_images({\"img\": [sample_image]})\n",
        "\n",
        "print(f\"Original image shape: {np.array(sample_image).shape}\")\n",
        "print(f\"Processed image shape: {processed_image['pixel_values'].shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Data Formatting for Hugging Face\n",
        "\n",
        "To train models with Hugging Face, we need to format our data appropriately. This typically involves:\n",
        "\n",
        "1. Converting labels to numeric format\n",
        "2. Tokenizing text data\n",
        "3. Creating train/validation/test splits\n",
        "\n",
        "Let's prepare our text classification dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load a tokenizer for text classification\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Function to tokenize text and prepare for the model\n",
        "def tokenize_function(examples):\n",
        "    \"\"\"Tokenize text data for the model\"\"\"\n",
        "    return tokenizer(\n",
        "        examples[\"processed_text\"],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        max_length=128\n",
        "    )\n",
        "\n",
        "# Convert labels to numeric format\n",
        "def convert_labels(examples):\n",
        "    \"\"\"Convert sentiment labels to numeric format\"\"\"\n",
        "    label_map = {\"negative\": 0, \"positive\": 1}\n",
        "    return {\"label\": label_map[examples[\"sentiment\"]]}\n",
        "\n",
        "# Apply both functions to the dataset\n",
        "tokenized_dataset = processed_dataset.map(convert_labels)\n",
        "tokenized_dataset = tokenized_dataset.map(tokenize_function, batched=True)\n",
        "\n",
        "# Keep only the necessary columns\n",
        "tokenized_dataset = tokenized_dataset.remove_columns(\n",
        "    [\"review_id\", \"category\", \"rating\", \"review_text\", \"sentiment\", \"processed_text\", \"__index_level_0__\"]\n",
        ")\n",
        "\n",
        "# Set the format for PyTorch\n",
        "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
        "\n",
        "print(tokenized_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's prepare our image classification dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare CIFAR-10 for training\n",
        "def prepare_cifar10(examples):\n",
        "    \"\"\"Prepare CIFAR-10 images for training\"\"\"\n",
        "    # Process images\n",
        "    inputs = image_processor(examples[\"img\"], return_tensors=\"pt\")\n",
        "    inputs[\"labels\"] = examples[\"label\"]\n",
        "    return inputs\n",
        "\n",
        "# Apply to a small subset for demonstration\n",
        "small_cifar = cifar10_dataset[\"train\"].select(range(1000))\n",
        "small_cifar_val = cifar10_dataset[\"test\"].select(range(200))\n",
        "\n",
        "# Create a smaller dataset for demonstration\n",
        "cifar_small = DatasetDict({\n",
        "    \"train\": small_cifar,\n",
        "    \"validation\": small_cifar_val\n",
        "})\n",
        "\n",
        "# Prepare the dataset\n",
        "prepared_cifar = cifar_small.map(prepare_cifar10, batched=True)\n",
        "prepared_cifar = prepared_cifar.remove_columns([\"img\", \"id\"])\n",
        "prepared_cifar = prepared_cifar.with_format(\"torch\")\n",
        "\n",
        "print(prepared_cifar)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Selecting a Base Model\n",
        "\n",
        "Choosing the right pre-trained model is crucial for successful fine-tuning. The selection depends on your task, data, and computational constraints."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1 Criteria for Selecting Pre-trained Models\n",
        "\n",
        "Consider these factors when selecting a base model:\n",
        "\n",
        "1. **Task Compatibility**: Choose a model pre-trained on a task similar to yours\n",
        "2. **Domain Relevance**: Consider models trained on data from your domain\n",
        "3. **Model Size**: Larger models generally perform better but require more resources\n",
        "4. **Computational Requirements**: Consider your hardware constraints\n",
        "5. **Community Support**: Popular models have better documentation and resources\n",
        "\n",
        "### 3.2 Model Architectures for Different Tasks\n",
        "\n",
        "| Task | Common Architectures | Example Models |\n",
        "|------|---------------------|----------------|\n",
        "| Text Classification | BERT, RoBERTa, DistilBERT | distilbert-base-uncased, roberta-base |\n",
        "| Named Entity Recognition | BERT, RoBERTa, LUKE | bert-base-NER, roberta-large |\n",
        "| Question Answering | BERT, RoBERTa, T5 | deepset/roberta-base-squad2, t5-base |\n",
        "| Text Generation | GPT-2, T5, BART | gpt2, t5-base, facebook/bart-large |\n",
        "| Image Classification | ResNet, ViT, Swin | google/vit-base-patch16-224, microsoft/resnet-50 |\n",
        "| Object Detection | DETR, Faster R-CNN | facebook/detr-resnet-50, faster-rcnn |\n",
        "| Image Segmentation | SegFormer, DeepLabV3 | nvidia/segformer-b0-finetuned-ade-512-512 |\n",
        "| Speech Recognition | Wav2Vec2, HuBERT | facebook/wav2vec2-base-960h |\n",
        "\n",
        "### 3.3 Browsing Models on the Hugging Face Hub\n",
        "\n",
        "The Hugging Face Hub hosts thousands of pre-trained models. You can browse them at https://huggingface.co/models.\n",
        "\n",
        "Let's see how to programmatically explore models for our tasks:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import the HfAPI to search for models\n",
        "from huggingface_hub import HfApi\n",
        "\n",
        "api = HfApi()\n",
        "\n",
        "# Search for text classification models\n",
        "text_models = api.list_models(filter=\"text-classification\", sort=\"downloads\", direction=-1, limit=5)\n",
        "\n",
        "print(\"Top 5 Text Classification Models:\")\n",
        "for model in text_models:\n",
        "    print(f\"- {model.id} (Downloads: {model.downloads})\")\n",
        "\n",
        "# Search for image classification models\n",
        "image_models = api.list_models(filter=\"image-classification\", sort=\"downloads\", direction=-1, limit=5)\n",
        "\n",
        "print(\"\\nTop 5 Image Classification Models:\")\n",
        "for model in image_models:\n",
        "    print(f\"- {model.id} (Downloads: {model.downloads})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For our text classification task, we'll use `distilbert-base-uncased`, a smaller, faster version of BERT that still performs well. For image classification, we'll use `google/vit-base-patch16-224`, a Vision Transformer model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Training and Fine-tuning\n",
        "\n",
        "Now that we have our data prepared and have selected our base models, let's implement the fine-tuning process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1 Text Classification Fine-tuning\n",
        "\n",
        "We'll fine-tune DistilBERT on our product reviews dataset for sentiment analysis:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the pre-trained model for sequence classification\n",
        "model_name = \"distilbert-base-uncased\"\n",
        "num_labels = 2  # binary classification (positive/negative)\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_name, \n",
        "    num_labels=num_labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define metrics for evaluation\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    \"\"\"Compute metrics for evaluation\"\"\"\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    \n",
        "    # Calculate multiple metrics\n",
        "    accuracy = accuracy_score(labels, predictions)\n",
        "    f1 = f1_score(labels, predictions, average=\"weighted\")\n",
        "    precision = precision_score(labels, predictions, average=\"weighted\")\n",
        "    recall = recall_score(labels, predictions, average=\"weighted\")\n",
        "    \n",
        "    return {\n",
        "        \"accuracy\": accuracy,\n",
        "        \"f1\": f1,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/sentiment_model\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,  # Set to True if you want to upload to Hugging Face Hub\n",
        "    report_to=\"none\"  # Disable reporting to avoid dependencies\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the model\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate on the test set\n",
        "test_results = trainer.evaluate(tokenized_dataset[\"test\"])\n",
        "print(f\"Test results: {test_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the model\n",
        "trainer.save_model(\"./final_model/sentiment_model\")\n",
        "tokenizer.save_pretrained(\"./final_model/sentiment_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Image Classification Fine-tuning\n",
        "\n",
        "Now let's fine-tune a Vision Transformer (ViT) model on the CIFAR-10 dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the pre-trained model for image classification\n",
        "model_name = \"google/vit-base-patch16-224\"\n",
        "num_labels = 10  # CIFAR-10 has 10 classes\n",
        "\n",
        "# Get label names for CIFAR-10\n",
        "label_names = cifar10_dataset[\"train\"].features[\"label\"].names\n",
        "print(f\"CIFAR-10 classes: {label_names}\")\n",
        "\n",
        "# Load the model with the correct number of labels\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    model_name,\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True  # Important when changing the number of labels\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configure training arguments for image classification\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results/cifar10_model\",\n",
        "    learning_rate=5e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=3,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        "    push_to_hub=False,\n",
        "    report_to=\"none\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize the Trainer for image classification\n",
        "image_trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=prepared_cifar[\"train\"],\n",
        "    eval_dataset=prepared_cifar[\"validation\"],\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the image classification model\n",
        "image_trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the image classification model\n",
        "image_test_results = image_trainer.evaluate()\n",
        "print(f\"Image classification results: {image_test_results}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save the image classification model\n",
        "image_trainer.save_model(\"./final_model/cifar10_model\")\n",
        "image_processor.save_pretrained(\"./final_model/cifar10_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Evaluation\n",
        "\n",
        "Now that we've trained our models, let's evaluate them more thoroughly and perform error analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1 Text Classification Evaluation\n",
        "\n",
        "Let's evaluate our sentiment analysis model on the test set and analyze its errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions on the test set\n",
        "predictions = trainer.predict(tokenized_dataset[\"test\"])\n",
        "preds = np.argmax(predictions.predictions, axis=-1)\n",
        "\n",
        "# Get the original texts and true labels\n",
        "test_df = df[train_size+val_size:].reset_index(drop=True)\n",
        "test_texts = test_df[\"review_text\"].tolist()\n",
        "true_labels = [1 if s == \"positive\" else 0 for s in test_df[\"sentiment\"].tolist()]\n",
        "\n",
        "# Create a DataFrame with predictions\n",
        "results_df = pd.DataFrame({\n",
        "    \"text\": test_texts,\n",
        "    \"true_label\": true_labels,\n",
        "    \"predicted_label\": preds,\n",
        "    \"correct\": np.equal(true_labels, preds)\n",
        "})\n",
        "\n",
        "# Calculate overall accuracy\n",
        "accuracy = accuracy_score(true_labels, preds)\n",
        "print(f\"Overall accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Look at the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "cm = confusion_matrix(true_labels, preds)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Negative\", \"Positive\"])\n",
        "disp.plot(cmap=\"Blues\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Error analysis: look at misclassified examples\n",
        "errors_df = results_df[~results_df[\"correct\"]].copy()\n",
        "print(f\"Number of errors: {len(errors_df)} out of {len(results_df)} examples\")\n",
        "\n",
        "# Add human-readable labels\n",
        "errors_df[\"true_sentiment\"] = errors_df[\"true_label\"].map({0: \"Negative\", 1: \"Positive\"})\n",
        "errors_df[\"predicted_sentiment\"] = errors_df[\"predicted_label\"].map({0: \"Negative\", 1: \"Positive\"})\n",
        "\n",
        "# Display some misclassified examples\n",
        "print(\"\\nSample of misclassified examples:\")\n",
        "sample_errors = errors_df.sample(min(5, len(errors_df)))\n",
        "for i, row in sample_errors.iterrows():\n",
        "    print(f\"\\nText: {row['text']}\")\n",
        "    print(f\"True sentiment: {row['true_sentiment']}\")\n",
        "    print(f\"Predicted sentiment: {row['predicted_sentiment']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Image Classification Evaluation\n",
        "\n",
        "Now let's evaluate our image classification model and analyze its errors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get predictions on the validation set\n",
        "image_predictions = image_trainer.predict(prepared_cifar[\"validation\"])\n",
        "image_preds = np.argmax(image_predictions.predictions, axis=-1)\n",
        "true_image_labels = prepared_cifar[\"validation\"][\"labels\"]\n",
        "\n",
        "# Calculate accuracy\n",
        "image_accuracy = accuracy_score(true_image_labels, image_preds)\n",
        "print(f\"Image classification accuracy: {image_accuracy:.4f}\")\n",
        "\n",
        "# Confusion matrix\n",
        "image_cm = confusion_matrix(true_image_labels, image_preds)\n",
        "image_disp = ConfusionMatrixDisplay(\n",
        "    confusion_matrix=image_cm, \n",
        "    display_labels=label_names\n",
        ")\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "image_disp.plot(ax=ax, cmap=\"Blues\")\n",
        "plt.title(\"CIFAR-10 Confusion Matrix\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some misclassified images\n",
        "misclassified_indices = np.where(image_preds != true_image_labels)[0]\n",
        "print(f\"Number of misclassified images: {len(misclassified_indices)} out of {len(true_image_labels)}\")\n",
        "\n",
        "# Display some misclassified examples\n",
        "if len(misclassified_indices) > 0:\n",
        "    num_examples = min(10, len(misclassified_indices))\n",
        "    fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "    axes = axes.flatten()\n",
        "    \n",
        "    for i, idx in enumerate(misclassified_indices[:num_examples]):\n",
        "        # Get the original image\n",
        "        original_idx = cifar_small[\"validation\"][idx][\"id\"]\n",
        "        img = cifar10_dataset[\"test\"][original_idx][\"img\"]\n",
        "        \n",
        "        true_label = true_image_labels[idx]\n",
        "        pred_label = image_preds[idx]\n",
        "        \n",
        "        axes[i].imshow(img)\n",
        "        axes[i].set_title(f\"True: {label_names[true_label]}\\nPred: {label_names[pred_label]}\")\n",
        "        axes[i].axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Performance Comparison\n",
        "\n",
        "Let's compare our fine-tuned models to some baselines to understand the benefits of fine-tuning:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# For text classification, compare to a simple baseline (TF-IDF + LogisticRegression)\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Prepare data\n",
        "train_texts = train_df[\"review_text\"].tolist()\n",
        "train_labels = [1 if s == \"positive\" else 0 for s in train_df[\"sentiment\"].tolist()]\n",
        "\n",
        "test_texts = test_df[\"review_text\"].tolist()\n",
        "test_labels = [1 if s == \"positive\" else 0 for s in test_df[\"sentiment\"].tolist()]\n",
        "\n",
        "# Create a baseline model\n",
        "baseline_model = Pipeline([\n",
        "    (\"vectorizer\", TfidfVectorizer(max_features=5000)),\n",
        "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "\n",
        "# Train and evaluate\n",
        "baseline_model.fit(train_texts, train_labels)\n",
        "baseline_preds = baseline_model.predict(test_texts)\n",
        "baseline_accuracy = accuracy_score(test_labels, baseline_preds)\n",
        "\n",
        "print(f\"Baseline (TF-IDF + LogReg) accuracy: {baseline_accuracy:.4f}\")\n",
        "print(f\"Fine-tuned DistilBERT accuracy: {accuracy:.4f}\")\n",
        "print(f\"Improvement: {(accuracy - baseline_accuracy) * 100:.2f} percentage points\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Deployment\n",
        "\n",
        "Once you've fine-tuned and evaluated your model, the next step is to deploy it for inference. There are several options for deploying Hugging Face models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1 Local Inference\n",
        "\n",
        "The simplest deployment option is to load your saved model for local inference:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved sentiment analysis model\n",
        "from transformers import pipeline\n",
        "\n",
        "# Create a sentiment analysis pipeline\n",
        "sentiment_analyzer = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=\"./final_model/sentiment_model\",\n",
        "    tokenizer=\"./final_model/sentiment_model\"\n",
        ")\n",
        "\n",
        "# Test with some examples\n",
        "test_examples = [\n",
        "    \"This product is amazing! I love it.\",\n",
        "    \"Terrible quality, broke after one use.\",\n",
        "    \"Average product, nothing special but works fine.\"\n",
        "]\n",
        "\n",
        "# Run inference\n",
        "results = sentiment_analyzer(test_examples)\n",
        "\n",
        "# Display results\n",
        "for text, result in zip(test_examples, results):\n",
        "    label = \"Positive\" if result[\"label\"] == \"LABEL_1\" else \"Negative\"\n",
        "    print(f\"Text: {text}\")\n",
        "    print(f\"Sentiment: {label} (confidence: {result['score']:.4f})\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the saved image classification model\n",
        "image_classifier = pipeline(\n",
        "    \"image-classification\",\n",
        "    model=\"./final_model/cifar10_model\",\n",
        "    feature_extractor=\"./final_model/cifar10_model\"\n",
        ")\n",
        "\n",
        "# Test with some examples from CIFAR-10\n",
        "test_images = [cifar10_dataset[\"test\"][i][\"img\"] for i in range(5)]\n",
        "\n",
        "# Run inference\n",
        "image_results = image_classifier(test_images)\n",
        "\n",
        "# Display results\n",
        "fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n",
        "for i, (img, result) in enumerate(zip(test_images, image_results)):\n",
        "    axes[i].imshow(img)\n",
        "    top_label = result[0][\"label\"]\n",
        "    confidence = result[0][\"score\"]\n",
        "    axes[i].set_title(f\"{top_label}\\n{confidence:.2f}\")\n",
        "    axes[i].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2 Creating a Simple API with FastAPI\n",
        "\n",
        "For production use, you might want to create an API. Here's a simple example using FastAPI:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%writefile sentiment_api.py\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from transformers import pipeline\n",
        "import uvicorn\n",
        "\n",
        "# Define the request model\n",
        "class SentimentRequest(BaseModel):\n",
        "    text: str\n",
        "\n",
        "# Initialize FastAPI\n",
        "app = FastAPI(title=\"Sentiment Analysis API\")\n",
        "\n",
        "# Load the model at startup\n",
        "@app.on_event(\"startup\")\n",
        "def load_model():\n",
        "    global sentiment_analyzer\n",
        "    sentiment_analyzer = pipeline(\n",
        "        \"text-classification\",\n",
        "        model=\"./final_model/sentiment_model\",\n",
        "        tokenizer=\"./final_model/sentiment_model\"\n",
        "    )\n",
        "\n",
        "# Define the prediction endpoint\n",
        "@app.post(\"/predict\")\n",
        "def predict_sentiment(request: SentimentRequest):\n",
        "    try:\n",
        "        # Run inference\n",
        "        result = sentiment_analyzer(request.text)[0]\n",
        "        \n",
        "        # Convert to a more user-friendly format\n",
        "        sentiment = \"positive\" if result[\"label\"] == \"LABEL_1\" else \"negative\"\n",
        "        confidence = result[\"score\"]\n",
        "        \n",
        "        return {\n",
        "            \"text\": request.text,\n",
        "            \"sentiment\": sentiment,\n",
        "            \"confidence\": confidence\n",
        "        }\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "# Health check endpoint\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    return {\"status\": \"healthy\"}\n",
        "\n",
        "# Run the API server when the script is executed directly\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"sentiment_api:app\", host=\"0.0.0.0\", port=8000, reload=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To run this API, you would execute:\n",
        "\n",
        "```bash\n",
        "python sentiment_api.py\n",
        "```\n",
        "\n",
        "Then you can make requests to `http://localhost:8000/predict` with JSON data like `{\"text\": \"I love this product!\"}`. The API also provides automatic documentation at `http://localhost:8000/docs`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3 Model Optimization\n",
        "\n",
        "Before deploying to production, you might want to optimize your model for inference speed and memory usage. Common techniques include:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Quantization\n",
        "\n",
        "Quantization reduces the precision of the model weights, typically from 32-bit floating point to 8-bit integers, significantly reducing model size and improving inference speed with minimal impact on accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of dynamic quantization with PyTorch\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model\n",
        "model_path = \"./final_model/sentiment_model\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
        "\n",
        "# Apply dynamic quantization\n",
        "quantized_model = torch.quantization.quantize_dynamic(\n",
        "    model, \n",
        "    {torch.nn.Linear}, \n",
        "    dtype=torch.qint8\n",
        ")\n",
        "\n",
        "# Save the quantized model\n",
        "quantized_model_path = \"./final_model/sentiment_model_quantized\"\n",
        "quantized_model.save_pretrained(quantized_model_path)\n",
        "\n",
        "# Compare model sizes\n",
        "import os\n",
        "\n",
        "def get_model_size(path):\n",
        "    total_size = 0\n",
        "    for dirpath, dirnames, filenames in os.walk(path):\n",
        "        for f in filenames:\n",
        "            fp = os.path.join(dirpath, f)\n",
        "            total_size += os.path.getsize(fp)\n",
        "    return total_size / (1024 * 1024)  # Convert to MB\n",
        "\n",
        "original_size = get_model_size(model_path)\n",
        "quantized_size = get_model_size(quantized_model_path)\n",
        "\n",
        "print(f\"Original model size: {original_size:.2f} MB\")\n",
        "print(f\"Quantized model size: {quantized_size:.2f} MB\")\n",
        "print(f\"Size reduction: {(1 - quantized_size/original_size) * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pruning\n",
        "\n",
        "Pruning removes less important weights from the model, making it smaller and faster. This is often combined with fine-tuning to recover any lost accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Knowledge Distillation\n",
        "\n",
        "Knowledge distillation trains a smaller \"student\" model to mimic a larger \"teacher\" model, transferring the knowledge while reducing model size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4 Hugging Face Inference Endpoints\n",
        "\n",
        "For a fully managed solution, you can use Hugging Face Inference Endpoints, which provide scalable, serverless deployment of your models.\n",
        "\n",
        "To use this service:\n",
        "\n",
        "1. Push your model to the Hugging Face Hub\n",
        "2. Create an Inference Endpoint through the Hugging Face website\n",
        "3. Make API requests to your endpoint\n",
        "\n",
        "Here's how you would push your model to the Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of pushing a model to the Hugging Face Hub\n",
        "# Note: You need to be logged in with `huggingface-cli login`\n",
        "\n",
        "# Load the model and tokenizer\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"./final_model/sentiment_model\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"./final_model/sentiment_model\")\n",
        "\n",
        "# Push to the Hub (commented out as it requires authentication)\n",
        "# model.push_to_hub(\"your-username/sentiment-analysis-model\")\n",
        "# tokenizer.push_to_hub(\"your-username/sentiment-analysis-model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this notebook, we've covered the complete fine-tuning workflow using the Hugging Face ecosystem:\n",
        "\n",
        "1. **Introduction and Motivation**: We learned when and why to fine-tune pre-trained models\n",
        "2. **Data Collection and Preparation**: We explored different data sources and preprocessing techniques\n",
        "3. **Selecting a Base Model**: We discussed criteria for choosing the right pre-trained model\n",
        "4. **Training and Fine-tuning**: We implemented fine-tuning for both text and image classification\n",
        "5. **Evaluation**: We evaluated our models and analyzed their errors\n",
        "6. **Deployment**: We explored different deployment options, from local inference to APIs\n",
        "\n",
        "Fine-tuning pre-trained models is a powerful technique that allows you to leverage state-of-the-art models for your specific tasks with relatively little data and computational resources. The Hugging Face ecosystem makes this process accessible and efficient.\n",
        "\n",
        "Remember that the most critical component of successful fine-tuning is your dataset. Invest time in collecting and preparing high-quality, task-specific data, and you'll be rewarded with better model performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
